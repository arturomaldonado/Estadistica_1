---
title: 'Clase 3 y Trabajo práctico LaLonde (1996)'
author: "Arturo Maldonado"
date: "13/4/2021"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 1
    code_download: true
    theme: cosmo
    highlight: textmate
editor_options:
  markdown:
    wrap: sentence
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

------------------------------------------------------------------------

# Estimación puntual

De una variable numérica, la medida de tendencia central más útil es la media.
Por ejemplo, siguiendo con el ejemplo de @lalondeEvaluatingEconometricEvaluations1986, podemos calcular la media de ingresos antes y después de la intervención.

Primero leemos la base de datos.

```{r base}
library(rio)
LL <- import("https://raw.github.com/arturomaldonado/Estadistica_1.0/main/LL.csv")
```

Y calculamos las medias en ambos años.

```{r media}
mean(LL$re74)
mean(LL$re78)
```

La manera de describir una variable categórica es a través de una tabla de frecuencias.
Siguiendo con el artículo, se puede calcular la tabla de frecuencias de los individuos afroamericanos y de los latinos.

```{r tabla}
table(LL$black)
table(LL$hispanic)
```

El comando `table` nos ofrece las frecuencias absolutas.
Para obtener los porcentajes (las frecuencias relativas) se puede anidar este comando dentro de `prop.table`.

```{r tabla de frecuencias}
prop.table(table(LL$black))*100
prop.table(table(LL$hispanic))*100
```

Se encuentra que los participantes del estudio son mayoritariamente afroamericanos y minoritariamente latinos.

En el caso de las tablas de frecuencias, se puede hallar la proporción (una forma de llamar a los porcentajes) de cada categoría de la variable.
Esta muestra de individuos tendrá un 80.1% de afroamericanos y un 10.5% de latinos.

Tanto la media, como la proporción, son estimaciones puntuales, basados en los resultados de la muestra.
Es decir, estas son estimaciones correspondientes a las 722 observaciones que son parte de este estudio.
Sin embargo, esta muestra forma parte de un universo o población (el conjunto de individuos que carecen de habilidades laborales para insertarse en el mercado de trabajo), del que seguramente se quiere decir algo.

El proceso mediante el cual se parte de una muestra para decir algo de un universo o población es un proceso de inferencia y es parte de la estadística inferencial.
La estadística inferencial introduce la incertidumbre en los estimados, debido al hecho de estar trabajando con una muestra y no con el total de observaciones del universo.

## Un breve paseo por las probabilidades

Partimos del hecho que en el común de las investigaciones uno tiene que seleccionar un conjunto de observaciones que son parte del total, que es muy costoso e ineficiente hacer un estudio de la población completa.
A esto le sumamos el otro hecho que nuestras herramientas de recojo de información son imperfectas.
Un estudio transversal, por ejemplo, debería recoger información de los individuos en un corte en el tiempo, sin embargo, muchos estudios no son una "foto del momento" pues las observaciones toman tiempo y abarcan horas, días o semanas, sino meses.

Es por este motivo que para un estudio se selecciona "una" muestra, un conjunto de observaciones que son una fracción del total.
Esta única muestra es solo una de las múltiples muestras teóricas que se podrían seleccionar de un universo determinado.

Partamos de un ejemplo muy simple.
Para un universo de 5 personas, se pueden extraer 10 muestras de tamaño 2 diferentes.

![](c3.1.png)

La fórmula para calcular el número de muestras probables es la de combinatorias, que incluye el operador factorial.
Si aplicamos esta fórmula a un ejemplo de un universo más grande, por ejemplo, un salón de clase de 47 alumnos, donde se quiere saber cuántas muestras diferentes de tamaño 4 se pueden extraer.
Según la fórmula:

$$
\frac{47!} {(47-4)! 4!} = \frac{47!} {43! 4!} = \frac{47*46*45*44} {4*3*2} = 178365
$$

Para un sondeo de opinión, donde el universo son 20 millones de individuos y se quiere saber cuántas muestras diferentes de tamaño 1,500 se pueden extraer, este número de muestras es muuuuy grande.

Volviendo al ejemplo muy simple de 5 personas donde se quiere extraer una muestra de 2 y se quiere inferir los datos de la muestra de dos variables: sexo y edad.

Se tiene un universo de 5 individuos, cada uno con su sexo y edad.
En la población la proporción de hombres es de 60% y la media de edad es de 34 años.

![](c3.2.png)

Si queremos extraer una muestra de tamaño de 2 de ese universo, se tienen 10 posibles muestras, cada una tendrá una aproximación de la proporción de hombres y de la media de edad.
Dependiendo de qué muestra de todas las posibles sea la que se observa, los estadísticos serán una aproximación de los parámetros poblacionales.

En el caso de la proporción de hombres, se puede tabular los resultados de cada muestra probable.

| Resultados muestrales | Número de muestras que arrojaron ese resultado | Frecuencia |
|:---------------------:|:----------------------------------------------:|:-----------|
|          0%           |                       1                        | X          |
|          50%          |                       5                        | XXXXX      |
|         100%          |                       4                        | XXXX       |

Incluso se podría calcular un promedio de todas esas proporciones muestrales (100+50+100+...+50/10), y ese resultado sería 65%, un resultado algo cerca de la proporción poblacional de 60%.

Este mismo procedimiento se podría hacer para todas las 178,365 muestras probables de tamaño 4 de un universo de 47 alumnos.
Cada uno de los 47 alumnos será hombre o mujer y la proporción poblacional de hombres se puede calcular en ese total.
A su vez, cada muestra de 4, tendrá una proporción muestral que tendrá valores (0 si no hay ningún hombre, 25% si hay 1 hombre, 50% si hay 2 hombres, 75% si hay 3 hombres y 100% si todos son hombres).
Finalmente, se puede contar cuántas de las 178,365 muestras probables tuvieron 0%, 25%, 50%, 75% y 100% de hombres.
Esta distribución se llama "distribución de muestreo".

Si quisiéramos ampliar el tamaño de muestra a 10, entonces los resultados posibles serían, 0, 10, 20, 30, 40, 50, 60, 70, 80, 90 y 100%.
También podríamos contar cuántas muestras tienen estos resultados.

De un universo más grande, se puede plantear extraer muestras de tamaño más grande.
Por ejemplo, teóricamente se puede pensar que de un universo de 20 millones, se pueden extraer casi infinitas muestras de tamaño 1,500.
Cada una de estas muestras tendrá un estadístico que será una aproximación del parámetro.
Los estadísticos de todas estas casi infinitas muestras se pueden tabular y graficar.

## Teorema del límite central

Este teorema muestra que la distribución de muestreo se aproxima a una distribución normal, con centro en el parámetro, en la medida que el tamaño de muestra aumenta.

Por lo tanto, la distribución de muestreo de N grandes seguirá las características de cualquier curva normal.
Toda curva normal es simétrica y sabemos que si desde el centro se desplaza 1 desviación estándar en ambas direcciones, entre esos límites estarán el 68.3% de todas las observaciones.
Si se desplaza 2 desviaciones estándar en ambas direcciones, se acumularían el 95.4% de todas las observaciones.
Con 3 desviaciones estándar hacia ambos lados, se acumularía el 99.7% de todas las observaciones.

![](c3.3.png){width="510"}

Traduciendo a la distribución de muestreo, la idea es que si se tabulan y se hace un gráfico de barras de los resultados de todas las muestras probables, se tendría una curva normal con centro en el parámetro.
Sabríamos que si desde ese centro nos desplazamos 2 desviaciones estándar en ambas direcciones, entre esos límites estarían el 95% de todas las muestra probables.

# Estimación de intervalo

La distribución de muestreo es teórica, muy difícilmente se puede calcular en la realidad.
Regularmente tampoco sabemos los datos del universo.
Lo que tenemos a mano es 1 muestra observada.
Es decir, en un estudio de las muuuuuchas muestras probables, se selecciona 1 muestra.

En el caso de @lalondeEvaluatingEconometricEvaluations1986, por ejemplo, del universo de desempleados sin habilidades laborales, se seleccionó 1 muestra de 722 observaciones, de las muuuuchas muestras de 722 individuos de la población total.

Si teóricamente sabemos que en la distribución muestral, el 95% de todas las muestras están a +/- 2 desviaciones estándar[^1] del centro, que coincide con el parámetro poblacional, es muy probable que la única muestra que se ha observado sea parte de ese conjunto.
De hecho, se puede decir que se tiene 95% de probabilidades de que sea parte de ese grupo.

[^1]: En realidad es a +/- 2 errores estándar del centro.
    El error estándar se entiende como la desviación estándar de la distribución de muestreo.

Por lo tanto, si a partir del estadístico muestral, se aplica esta distancia de +/- 2 errores estándar, se tiene 95% de probabilidades que entre esos límites se incluya al valor del parámetro.
Para verlo de manera más visual, en la siguiente figura se tiene la distribución de muestreo teórica (y desconocida), donde se marca la región que acumula el 95% de todas las muestras probables.

Más abajo se marca los resultados de 2 muestras probables.
La primera proporción muestral subestima la proporción poblacional.
La segunda, por el contrario, sobreestima la proporción poblacional.
En el primer caso, si a partir del estadístico muestral se aplica +/- 1.96 errores estándar (línea horizontal en negrita), se observa que el parámetro poblacional está incluido en esos límites.

Es probable, como en el segundo caso, que otra muestra probable, cuando se le aplique el intervalo de +/- 1.96 errores estándar, no incluya al parámetro.
Se observa que la línea en negrita no incluye la linea vertical entrecortada que marca el valor del parámetro poblacional.

![](c3.4.png){width="581"}

Sin embargo, sabemos que es mucho más probable (95% de probabilidades) que si mi muestra es parte del 95% de muestras alrededor del parámetro, este intervalo incluya al parámetro poblacional.
A estos límites le llamamos "intervalos de confianza".

## Teoría en la práctica

Usaremos el ejemplo de @lalondeEvaluatingEconometricEvaluations1986 para graficar estas divagaciones teóricas.
Asumamos que la base de datos de este artículo es el universo de personas.
Las 722 personas en esa base de datos serían todos los miembros que se podrían escoger.
De ese universo, queremos extraer muestras de tamaño 100.
Según una calculadora de combinaciones, existen 5.7x10\^124 combinaciones de tamaño 100 de un universo de 722.
Hay menos átomos en el universo que muestras probables.

Sabemos cuál es el valor poblacional si calculamos la media de los 722 casos.

```{r edad}
mean(LL$age)
```

El parámetro es igual a 24.5 años.
Como ejemplo, calcularemos 3000 muestras para calcular el estadístico (la aproximación muestral) del parámetro de la variable edad y guardaremos todos esos resultados en un objeto de tipo vector.

```{r loop, message=FALSE, warning=FALSE}
library(dplyr)
x<-c(1:3000)
for (i in 1:3000) {
  sub <- sample_n(LL, 100, replace=F)
  x[i]<- mean(sub$age, na.rm=T) 
  rm(sub)
}
x
```

Cada uno de estos números corresponde a la media muestral de la variable edad de cada una de las 3000 muestras aleatorias que hemos calculado.
Vemos que algunas medias muestrasles subestiman y otras sobreestiman el valor del parámetro poblacional.
Si graficamos el histograma de todos estos valores, vemos que se dibuja una curva aproximadamente normal.

```{r distribución de muestreo}
hist(x)
```

## Intervalos de confianza

En cualquier investigación solo se cuenta con 1 muestra única, cuyo estadístico muestral, sea una media o un proporción, es una aproximación del parámetro poblacional.

Para poder extrapolar desde la muestra hasta la población, se tiene que construir un intervalo de confianza alrededor del estadístico muestral.
Este intervalo se construye aplicando la "distancia" de +/- 2 errores estándar, para tener una confianza de 95% de incluir al parámetro poblacional.

Si se está extrapolando para una variable numérica, mediante la media, el error estándar (o se) es:

$$
se = 1.96 * \frac{s} {\sqrt{n}}
$$

Si se está extrapolando para una variable categórica, mediante una proporción, el error estándar (o se) es:

$$
se = 1.96 * \sqrt{\frac{(p * (1-p))} {n}}
$$

A manera de resumen, la siguiente tabla nos muestra el parámetro, el estadístico puntual y el error estándar para cada tipo de variable y cómo se forma el intervalo de confianza.

![](c3.5.png)

En estas fórmulas, se usa el símbolo "t" y "z" para referir a las distribuciones teóricas que se usan.
Para fines prácticos, cuando la muestra es grande, ambas distribuciones son iguales.
El valor de "t" o "z" depende del nivel de confianza que queremos.
Es decir, de la probabilidad que queremos de que el intervalo incluya al parámetro.
De esta manera:

-   Z al 90% = 1.645

-   Z al 95% = 1.98

-   Z al 98% = 2.326

-   Z al 99% = 2.576

¿Qué para con el IC cuando se quiere mayor confianza?
¿Se vuelve más o menos preciso?

------------------------------------------------------------------------

# Ejemplo de LaLonde

En el trabajo de LaLonde se han recogido 722 observaciones de un universo desconocido, pero que se asume grande.
La idea es pasar de estimaciones puntuales a estimaciones por intervalos, es decir de datos que corresponden a los 722 participantes del estudio hacia el universo de personas sin habilidades laborales para insertarse en el mercado de trabajo.
Por ejemplo, los datos de los ingresos puntuales en el año 1974 y 1978 corresponden a esos 722 individuos.

```{r media 2}
mean(LL$re74)
mean(LL$re78)
```

Para extrapolar a la población, se tiene que construir el intervalo de confianza de cada media.
Para aplicar la fórmula, se requiere la desviación estándar y el N.
Sabemos que el N = 722, pues no hay valores perdidos para estas variables.
La desviación estándar la obtenemos con el comando `sd`.

```{r descriptivos}
sd(LL$re74)
sd(LL$re78)
```

Por lo tanto para los ingresos en 1974 se tendría:

$$
I.C. = media +/- t*se = 3630.7 +/- 1.96 * \frac{6220.6} {\sqrt{722}} = 3630.7 +/- 453.8
$$

-   Límite Inferior del IC es: 3630.7 - 453.8 = 3176.9

-   Límite Superior es: 3630.7 + 453.8 = 4084.5

Por lo tanto el IC es [3176.9, 4084.5] y asumimos que con ese rango tenemos 95% de confianza que incluya al parámetro poblacional desconocido.

El parámetro poblacional podría ser entendido como el promedio de ingresos en 1974 de TODOS los individuos sin habilidades laborales, si es que esa información fuera recogida de manera perfecta, es decir, en un mismo momento, en las mismas condiciones.

Como eso es imposible de hacer o poco eficiente, confiamos en el IC que se genera a partir de una muestra.

Para evitar el cálculo manual del IC, se puede usar el comando

```{r IC74}
library(lsr)
ci74 <- ciMean(LL$re74)
ci74
```

De la misma manera se puede calcular el IC de los ingresos en 1978.

```{r IC78}
ci78 <- ciMean(LL$re78)
ci78
```

Para variables categóricas, lo primero es inspeccionar las tablas de distribución de frecuencias, por ejemplo para la proporción (o porcentaje) de afroamericanos e hispanos en la muestra.
Se tiene 0.80 (o 80%) de afroamericanos y 0.105 (o 10.5%) de hispanos en la muestra.

```{r tablas}
prop.table(table(LL$black))
prop.table(table(LL$hispanic))
```

Para extrapolar estos resultados a la población, se puede aplicar la fórmula.
Por ejemplo, para los afroamericanos:

$$
I.C. = prop +/- z * se = 0.8 +/- 1.96 * \sqrt{\frac{0.8*0.2}{722}} = 0.8 +/- 0.029
$$

-   Límite inferior: 0.8 - 0.029 = 0.771 o 77.1%

-   Límite superior: 0.8 + 0.029 = 0.829 o 82.9%

Por lo tanto el IC es [77.1%, 82.9%] y asumimos que en ese rango se encuentra la proporción poblacional de afroamericanos al 95% de confianza.

En R no se cuenta con un comando particular para el cálculo directo de ICs de proporciones.
Pero, cuando las variables categóricas son variables "dummy", es decir codificadas como 0/1, entonces la media de la variable es igual a la proporción y se puede usar el comando `CI` para el cálculo del IC.

```{r IC proporción}
ciafro <- ciMean(LL$black)
cihisp <- ciMean(LL$hispanic)
ciafro
cihisp
```

Para los hispanos, se puede decir que la proporción poblacional está entre 8.3% y 12.8% al 95% de confianza.

# Bibliografía
