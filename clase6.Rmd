---
title: "Clase 7"
author: "Arturo Maldonado"
date: "2/05/2023"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 1
    code_download: true
    theme: cosmo
    highlight: textmate
editor_options:
  markdown:
    wrap: sentence
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

Hasta el momento se ha visto la prueba t para comparar medias de solo 2 grupos.
En esta sección veremos cómo expandir la comparación para varias medias usando otra prueba de inferencia.
Es decir, se busca analizar la relación entre una variable dependiente cuantitativa (o numérica) y una variable independiente categórica (o de factor).

La media de la variable dependiente es comparada para cada grupo de la variable independiente categórica, típicamente una variable nominal.
Por ejemplo:

-   Ingresos entre grupos étnicos.

-   CRAEST entre alumnos de especialidades de Ciencias Sociales.

-   Posición ideológica entre simpatizantes de diferentes partidos.

Para poder hacer estas comparaciones entre varios grupos vamos a usar el test del ANOVA

# Test de ANOVA

El test de ANOVA sirve para comparar la media de una variable dependiente numérica entre grupos de una variable de tipo factor (con más de 2 grupos).

Este test parte teóricamente de la distribución general de la variable numérica, la que tiene una media poblacional $\mu$, y compara esta media poblacional general, con las medias poblacionales de la variable numérica por cada grupo de la variable de factor con n grupos, $\mu_1...\mu_2...\mu_3...\mu_n$.

![](anova1.png){width="534"}

Esta prueba se basa en la distribución F y propone la siguiente hipótesis nula para la comparación de una variable numérica X entre n grupos de la variable de factor.

$$
H0: \mu_{x1} = \mu_{x2} = \mu_{x1} =...= \mu_{xn}
$$

La hipótesis alternativa que propone es que al menos una media poblacional de un grupo es diferente.
Es decir, si se rechaza la H0, quizá todas las medias poblacionales entre grupos sean distintas, quizá algunas o quizá solo una difiere de las otras.

Esta prueba se basa en una comparación entre la variabilidad entre (between) y la variabilidad intra (within).

## Variabilidad entre

-   La variabilidad entre se refiere a la comparación de la media muestral grupal $\overline{X}_1$ y la media general $\overline{X}$.

-   Se entiende como un promedio ponderado de las distancias $\overline{X_g}-\overline{X}$.

-   Para evitar que sea una distancia negativa se eleva al cuadrado $(\overline{X_g}-\overline{X})^2$.

-   Se pondera por el número de observaciones de cada grupo $n_g*(\overline{X_g}-\overline{X})^2$.

-   Se suma estas cantidades de cada grupo: $\sum n_g*(\overline{X_g}-\overline{X})^2$.

-   Esa suma se divide entre los grados de libertad g-1 (número de grupos -1).

## Variabilidad intra

-   Es la variabilidad entre las observaciones de cada grupo con su media grupal.

-   Se entiende como el cálculo de la desviación estándar en cada grupo.

-   Se calcula $\sum (X_i-\overline{X_g})^2$ en cada grupo.
    Estas sumatorias se suman.

-   Esa suma total se divide entre los grados de libertad N-g (total de observaciones - número de grupos).

## Estadístico de la prueba F

-   Se calcula como F = estimado de la variabilidad entre / estimado de la variabilidad intra

El estadístico F se hace grande cuando: hay mayor variabilidad entre y/o menos variabilidad intra.

El estadístico F se hace pequeño cuando: hay menor variabilidad entre y/o mayor variabilidad intra.

A medida que el estadístico F es más grande, se ubica más en la cola de la distribución, por lo que el p-value será menor, con los que se tendría una mayor evidencia en contra de la H0 sobre la igualdad de medias poblacionales.

![](anova2.png){width="534"}

Por lo tanto se concluiría que al menos una de las medias grupales sería significativamente diferente de las otras medias grupales.
El tema es que la prueba de ANOVA no llega hasta ahí, no nos indica qué medias son diferentes.
Para saber qué media(s) es(son) diferente(s) se tiene que hacer un test posterior.

## Post hoc: Test de Tukey

Este test sirve para analizar qué diferencias entre grupos son significativas.
Es decir, reporta todos los emparejamientos posibles entre grupos y en cada pareja calcula una prueba t de diferencia de medias y la reporta.

# Ejemplo para una variable numérica entre 2+ grupos

```{r base endo, message=FALSE, warning=FALSE}
library(rio)
endo2020 = import("bases/ENDO_REMOTO_2020.dta")
```

Si queremos evaluar si existen diferencias entre el número promedio de alumnos con los que trabaja un profesor entre tipos de profesores (nombrados, contratados con concurso o nombrados con otra modalidad), se puede usar ANOVA.

Primero se tiene que factorizar la variable tipo de profesor (P1_7).

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(tidyverse)
endo2020 = endo2020 |>
  mutate(tipo = factor(P1_7, labels=c("Nombrado", "Contratado por concurso",
                                      "Contratado por otra modalidad")))
```

```{r}
alumxtipo = endo2020 |> 
  group_by(tipo) |>
  summarize(media = mean(P1_6, na.rm = T))
alumxtipo
```

```{r}
alumxtipo = alumxtipo[-4, ]
```

Para tener una descripción completa entre los 3 grupos, también se puede usar:

```{r}
library(Rmisc)
alumnos.tipo = group.CI(P1_6~tipo, endo2020)
alumnos.tipo
```

¿Qué conclusiones "informales" se pueden sacar del gráfico?

```{r}
library(ggplot2)
graf1 = ggplot(alumnos.tipo, aes(x=tipo, y=P1_6.mean))+
  geom_bar(stat="identity")+
  geom_errorbar(aes(ymin=P1_6.lower, ymax=P1_6.upper), width=0.2)+
  geom_text(aes(label=paste(round(P1_6.mean, 1))), vjust=-1, size=3)+
  xlab("Tipo del contrato") + ylab("Alumnos atendidos")+
  ylim(0, 80)
graf1
```

Esta observación visual se tiene que confirmar con la prueba de ANOVA.
Para esto se usa el comando `aov` para crear un objeto "anova1" que luego se describe con `summary`.

```{r anova alumnos x tipo}
anova1 = aov(endo2020$P1_6~endo2020$tipo)
summary(anova1)
```

Con la prueba de ANOVA y dado que el p-value es menor a 0.05, se puede rechazar la H0.
Es decir, se afirma la Ha de que al menos una de las diferencias es significativa.
ANOVA no nos indica cuál es la(s) diferencia(s) significativa(s).

Para evaluar las diferencias, se corre la prueba de Tukey para analizar cada emparejamiento.
Esto se hace con el comando `TukeyHSD` en el que se inserta el objeto "anova1" y con el cual se crea un objeto "compara".

```{r Tukey alumnos x tipo}
compara = TukeyHSD(anova1)
compara
```

Se observa que los resultados comprueban las observaciones del gráfico.
Cada emparejamiento tiene un valor de la diferencia de medias "diff", un límite inferior "lwr" y límite superior "upr" del intervalo de confianza de esa diferencia y un p-value "p adj".
Este último valor es el que se evalúa para saber si el emparejamiento tiene una diferencia estadísticamente significativa.
Se observa que el emparejamiento "Contratado por concurso-Nombrado" tiene un p-value muy pequeño (no es cero, solo faltan decimales), por lo que podemos rechazar la Ho y afirmar que sí existen diferencias en el número de alumnos con los que trabajan estos tipo de profesores.

El emparejamiento entre "Contratado por otra modalidad-Nombrado" tiene un p-value de 0.02, que es menor que 0.05, por lo que concluimos que también existen diferencias en el número de alumnos promedio con el que trabajan estos tipos de profesores.

El emparejamiento "Contratado por otra modalidad-Contratado por concurso" tiene un p-value = 0.36 que es mayor que 0.05, por lo que no se puede concluir que haya diferencias en el promedio de alumnos con los que trabajan estos tipos de profesores.

Estos emparejamientos se pueden graficar con el comando `plot`, donde se inserta el código de Tukey.

```{r}
plot(TukeyHSD(anova1))
```

Aquellos emparejamientos cuyas líneas no crucen la línea vertical del cero, se puede decir que hay diferencias estadísticamente significativas.

Este gráfico también se puede reproducir con la librería `ggplot`.
Para esto, primero, se tiene que transformar el objeto "compara" (que es una lista) en un dataframe, con el comando `as.data.frame` y se crea un nuevo objeto "compara.df", que tiene los valores que requerimos para graficar, excepto que el nombre de las comparaciones esta como nombre de las filas y no como variable.
Para incluir las comparaciones como una variable se usa el comando `rownames` y se crea una nueva columna `compara.df$compara`.

```{r}
compara.df = as.data.frame(compara[1])
compara.df$compara = rownames(compara.df)
```

Con este dataframe, podemos usar la librería `ggplot` para graficar los intervalos de confianza de las diferencias de medias.

```{r}
graf2 = ggplot(compara.df, aes(x=compara, y=diff))+
  geom_errorbar(aes(ymin=lwr, ymax=upr), width=0.2)+
  geom_text(aes(label=paste(round(diff, 1))), vjust=-1, size=3)+
  xlab("Comparación") + ylab("Diferencia")+
  ylim(-10, 40) +
  coord_flip() +
  geom_hline(yintercept = 0, color = "red", linetype="dotted") +
  theme_classic()
graf2
```

# Otro ejemplo

En esta sección seguiremos usando el paper de [@lalondeEvaluatingEconometricEvaluations1986] para evaluar los ingresos.
En la sección anterior se encontró que había una diferencia estadísticamente significativa entre los afros y no afros en sus ingresos en 1978.

```{r base LL}
library(rio)
LL = import("bases/LL.csv")
```

Adicionalmente, se puede evaluar si existen diferencias extrapolables entre aquellos con un grado académico y aquellos que no.
Para esto se vuelve a usar la prueba t entre estos dos grupos.
En primer lugar, se evalúa si las varianzas son iguales o no.
Ojo, el código lanza un mensaje que indica que la variable "degree" no es un factor, y, efectivamente, es importanda como una variable de tipo "int", pero es coercionada como factor, pues R identifica que solo tiene 2 valores.

```{r Levene 1}
library(DescTools)
LeveneTest(LL$re78, LL$nodegree)
```

El resultado indica que se puede rechazar la hipótesis de igualdad de varianzas y asumir que son diferentes.
Con esto se corre la prueba t.

```{r t 1}
t.test(re78 ~ nodegree, data = LL, var.equal=F)
```

Se encuentra que sí hay diferencias entre aquellos con un grado académico y aquellos que no.
Ahora lo que queremos evaluar es si existen diferencias entre los afroamericanos con grado académico y sin grado académico y los no afroamericanos con grado y sin grado.
Para hacer esta evaluación entre 4 grupos, lo primero es construir la variable que es la combinación de las variables "black" y "nodegree".

```{r afro x grado}
LL$axd <-NA
LL$axd[LL$black==0 & LL$nodegree==0] <- 1 #no afro sin grado
LL$axd[LL$black==0 & LL$nodegree==1] <- 2 #no afro con grado
LL$axd[LL$black==1 & LL$nodegree==0] <- 3 #afro sin grado
LL$axd[LL$black==1 & LL$nodegree==1] <- 4 #afro con grado
```

La variable creada es una variable numérica, la que se convierte a factor y se etiqueta.

```{r factor afro x grado}
LL$axd <- as.factor(LL$axd)
levels(LL$axd) <- c("No afro s/grado", "No afro c/grado", "Afro s/grado", "Afro c/grado")
table(LL$axd)
```

Antes de correr la prueba, es una buena práctica hacer una inspección descriptiva de los ingresos entre estos 4 grupos.

```{r message=FALSE, warning=FALSE}
library(psych)
tabla1 <- describeBy(LL$re78, group=LL$axd)
tabla1
```

O también se puede hacer una inspección visual.
A primera vista, no parece haber diferencias entre ningún grupo, en cuanto a ingresos.

```{r medias afro x grado}
library(gplots)
plotmeans(LL$re78~LL$axd, connect=F, barwidth=3, xlab="Grupos", ylab="Ingresos 1978",
          main="Ingresos por grupos")
```

Esta observación visual se tiene que confirmar con la prueba de ANOVA.

```{r anova afro x grado}
anova1 <- aov(LL$re78~LL$axd)
summary(anova1)
```

Con la prueba de ANOVA y el p-value correspondiente no se puede rechazar la H0.
Este p-value sí sería significativo a 0.10, pero tendríamos una probabilidad mayor de error de tipo I.
Para confirmar esto, se corre la prueba de Tukey para analizar cada emparejamiento.

```{r Tukey afro x grado}
TukeyHSD(anova1)
```

En este caso se observa que la diferencia entre afroamericanos con grado y no afroamericanos con grado es la que explica que ANOVA sea marginalmente significativo.

NOTA: Hay ocasiones como esta en que la prueba de ANOVA indica que existe un emparejamiento con una diferencia significativa, y luego, cuando se evalúan los emparejamientos, no se observa esa diferencia.
Eso es debido a que cada emparejamiento de evalúa mediante la prueba t de manera autónoma.

# Para una variable categórica

De la misma manera que en la sección anterior, ANOVA también se puede utilizar de manera **referencial** para evaluar las diferencias de proporciones entre más de 2 grupos.
Por ejemplo, el último informe del Barómetro de las Américas del Proyecto de Opinión Pública en América Latina, disponible [aquí](https://iep.org.pe/wp-content/uploads/2021/04/Peru.-Cultura-politica-de-la-democracia-2021.pdf), presenta esta gráfico sobre satisfacción con la democracia en Perú a lo largo del tiempo.

![](Grafico6.2.png){width="591"}

Como indica el informe, la satisfacción con la democracia se mide con la pregunta: En general, usted diría que está muy satisfecho(a), satisfecho(a), insatisfecho(a) o muy insatisfecho(a) con la forma en que la democracia funciona en Perú?
Este pregunta se recodifica en otra variable que agrupa a aquellos que están satisfechos o muy satisfechos.
El porcentaje de este grupo es lo que se muestra en el gráfico a lo largo de los años.
Es decir, se está comparando esta porcentaje por años.

Para evaluar si existen diferencias en la satisfacción con la democracia en Perú y entre qué años se puede decir que haya diferencia, lo primero es cargar la base de datos del Barómetro para Perú.

```{r lapop}
lapop <- import("bases/PER_2006-2021.dta")
```

La variable que mide la satisfacción con la democracia es "pn4".
En primer lugar, vamos a describir la variable.

```{r pn4}
table(lapop$pn4)
```

Los códigos numéricos referidos a "satisfecho" y "muy satisfecho" son el 1 y 2.
Se tiene que crear una nueva variable donde estos códigos numéricos sean recodificados como 100.

```{r recodificar pn4}
lapop$pn4rec = car::recode(lapop$pn4, "1:2=100; 3:4=0")
table(lapop$pn4rec)
```

Con esta variable podemos calcular la media de la satisfacción con la democracia en Perú, que es el porcentaje, para todas las rondas del Barómetro.

```{r media pn4}
mean(lapop$pn4rec, na.rm = T)
```

También se podría calcular el porcentaje de satisfacción con la democracia por año.
La variable que indica el año es "year".
Antes de calcular, la variable "year" es cargada como una variable numérica, de tipo "num".
Para poder operar en anova, esta variable se tiene que convertir en una variable de tipo factor.

```{r year}
lapop$year = as.factor(lapop$year)
table(lapop$year)
```

Ahora, calculamos los porcentajes de satisfacción con la democracia por años.

```{r tabla pn4}
tabla2 = describeBy(lapop$pn4rec, group=lapop$year)
tabla2
```

También se puede crear un gráfico de comparación de media.
En la especificación `connect=T` indica que queremos que los porcentajes de satisfacción con la democracia se conecten, de la misma manera que en el gráfico 6.2.

```{r grafico pn4}
library(gplots)
plotmeans(lapop$pn4rec~lapop$year, connect=T, barwidth=3, xlab="Año", 
          ylab="Satisfacción con la democracia",
          ylim=c(0, 100))
```

Para formalizar la comparación de satisfacción con la democracia por años, calculamos la prueba de anova.
El p-value \< 0.05.
Esto nos lleva a poder rechazar la H0 de igualdad de medias grupales poblacionales.
Por lo tanto concluimos que alguna de estas medias grupales es diferente.
Es decir, podemos concluir que al menos un porcentaje de satisfacción con la democracia es diferente entre los años en Perú.

```{r anova pn4}
anova2 <- aov(lapop$pn4rec~lapop$year)
summary(anova2)
```

Para comprobar que diferencias entre años particulares son estadísticamente significativas, calculamos la prueba post-hoc de Tukey.
Esta tabla nos muestra que hay varios emparejamientos entre años que tienen unb p-value \< 0.05, por ejemplo, la diferencia en satisfacción con la democracia entre 2006 y 2012 o esta diferencia entre 2008 y 2012.

```{r}
TukeyHSD(anova2)
```

Siguiendo con el ejemplo sobre discriminación en CVs [@bertrandAreEmilyGreg2004] que buscan evaluar si hay una discriminación en el mercado laboral entre afroamericanos y angloamericanos y entre hombres y mujeres.
Estos investigadores enviaron CVs manipulando la raza y el género percibidos mediante nombres claramente asociados a los afroamericanos y nombres claramente asociados a angloamericanos, tanto nombres masculinos como femeninos.

En la sección anterior se encontró que sí había un sesgo en contra de los afroamericanos, pero que no se podía decir que hubiera un sesgo en contra de las mujeres en el mercado laboral.
En los resultados comparando género, cuando se compara hombre y mujeres, en ambos grupos hay afroamericanos y angloamericanos.

Una posibilidad es que haya una discriminación en el mercado laboral aún mayor en contra de las mujeres afroamericanos con respecto a los hombres afroamericanos, y de estos con respecto a los angloamericanos, sean hombre o mujeres.
Es decir, que la tasa de respuesta a CVs sería menor para las mujeres afro que para los hombres afro y estos menores que la tasa de respuesta a los CVs de hombre o mujeres angloamericanos.

Para evaluar esta hipótesis, primero cargamos nuevamente la base de datos.

```{r base, message=FALSE, warning=FALSE}
library(rio)
cv <- import("https://raw.github.com/arturomaldonado/Estadistica_1.0/main/cv.csv")
```

En esta base de datos se tiene la raza y el género como variables separadas.
Para hacer la evaluación que se busca se requiere crear una nueva variable de factor que combine los 4 grupos de raza y género.
Se tiene que prestar atención a la forma de calcular una variable como condición de las variables "race" y "sex", ambas de tipo "chr".

```{r factor}
cv$rxg <- NA
cv$rxg[cv$race=="black" & cv$sex=="female"] <- 1
cv$rxg[cv$race=="black" & cv$sex=="male"] <- 2
cv$rxg[cv$race=="white" & cv$sex=="female"] <- 3
cv$rxg[cv$race=="white" & cv$sex=="male"] <- 4
cv$rxg = as.factor(cv$rxg)
levels(cv$rxg) <- c("Black woman", "Black man", "White woman", "White man")
table(cv$rxg)
```

Lo primero es recordar que la tasa de respuesta general es de 8% para toda la muestra.

```{r tasa}
mean(cv$call)*100
```

Ahora podemos calcular la tasa de respuesta a los CVs por cada grupo.
Esta comparación se puede guardar en un objeto "tabla1".

```{r tasa por grupos}
library(psych)
tabla2 <- describeBy(cv$call*100, group=cv$rxg)
tabla2
```

También se puede ver esta comparación descriptiva en forma de gráfico.

```{r plot}
library(gplots)
plotmeans(cv$call*100~cv$rxg, connect=F, barwidth=3, xlab="Grupos", ylab="Tasa de respuesta",
          ylim=c(0, 15), main="Tasa de respuesta por grupos")
```

Para comprobar esta comparación "informal" se tiene que correr el test de ANOVA.

```{r anova}
anova3 <- aov(cv$call*100~cv$rxg)
summary(anova3)
```

Se obtiene un estadístico F de 5.97, con lo que se calcula un p-value \< 0.05.
Esto nos lleva a poder rechazar la H0 de igualdad de medias grupales poblacionales.
Por lo tanto concluimos que alguna de estas medias grupales es diferente.

Para saber cuál es diferente se tiene que correr el Test de Tukey.

```{r tukey}
TukeyHSD(anova3)
```

Este test nos brinda resultados por cada emparejamiento.
Se concluye que hay 2 emparejamientos relevantes, que llevan a la conclusión que las mujeres blancas tienen una tasa de respuesta mayor que los hombre y mujeres afro.

Estas diferencias se pueden ver de manera gráfica.

```{r plot Tukey}
plot(TukeyHSD(anova3))
```

Aquellos emparejamientos cuyas líneas no crucen la línea vertical del cero, se puede decir que hay diferencias estadísticamente significativas.
