---
title: "Clase 6"
author: "Arturo Maldonado"
date: "5/3/2021"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 1
    code_download: true
    theme: cosmo
    highlight: textmate
editor_options:
  markdown:
    wrap: sentence
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

Hasta el momento se ha visto una prueba, la prueba t, para comparar medias de solo 2 grupos.
En esta sección veremos cómo expandir la comparación para varias medias usando otra prueba de inferencia.
Es decir, se busca analizar la relación entre una variable dependiente cuantitativa (o numérica) y una variable independiente categórica (o de factor).

La media de la variable dependiente es comparada para cada grupo de la variable independiente categórica, típicamente una variable nominal.
Por ejemplo:

-   Ingresos entre grupos étnicos.

-   CRAEST entre alumnos de especialidades de Ciencias Sociales.

-   Posición ideológica entre simpatizantes de diferentes partidos.

Para poder hacer estas comparaciones entre varios grupos vamos a usar el test del ANOVA

# Test de ANOVA

El test de ANOVA sirve para comparar la media (o la proporción de una variable dummy) de una variable dependiente numérica entre grupos de una variable de tipo factor (con más de 2 grupos.

Este test parte teóricamente de la distribución general de la variable numérica, la que tiene una media poblacional $\mu$, y compara esta media poblacional general, con las medias poblacionales de la variable numérica por cada grupo de la variable de factor con n grupos, $\mu_1...\mu_2...\mu_3...\mu_n$.

![](anova1.png){width="534"}

Esta prueba se basa en la distribución F y propone la siguiente hipótesis nula para la comparación de una variable numérica X entre n grupos de la variable de factor.

$$
H0: \mu_{x1} = \mu_{x2} = \mu_{x1} =...= \mu_{xn}
$$

La hipótesis alternativa que propone es que al menos una media poblacional de un grupo es diferente.
Es decir, si se rechaza la H0, quizá todas las medias poblacionales entre grupos sean distintas, quizá algunas o quizá solo una difiere de las otras.

Esta prueba se basa en una comparación entre la variabilidad entre (between) y la variabilidad intra (within).

## Variabilidad entre

-   La variabilidad entre se refiere a la comparación de la media muestral grupal $\overline{X}_1$ y la media general $\overline{X}$.

-   Se entiende como un promedio ponderado de las distancias $\overline{X_g}-\overline{X}$.

-   Para evitar que sea una distancia negativa se eleva al cuadrado $(\overline{X_g}-\overline{X})^2$.

-   Se pondera por el número de observaciones de cada grupo $n_g*(\overline{X_g}-\overline{X})^2$.

-   Se suma estas cantidades de cada grupo: $\sum n_g*(\overline{X_g}-\overline{X})^2$.

-   Esa suma se divide entre los grados de libertad g-1 (número de grupos -1).

## Variabilidad intra

-   Es la variabilidad entre las observaciones de cada grupo con su media grupal.

-   Se entiende como el cálculo de la desviación estándar en cada grupo.

-   Se calcula $\sum (X_i-\overline{X_g})^2$ en cada grupo.
    Estas sumatorias se suman.

-   Esa suma total se divide entre los grados de libertad N-g (total de observaciones - número de grupos).

## Estadístico de la prueba F

-   Se calcula como F = estimado de la variabilidad entre / estimado de la variabilidad intra

El estadístico F se hace grande cuando: hay mayor variabilidad entre y/o menos variabilidad intra.

El estadístico F se hace pequeño cuando: hay menor variabilidad entre y/o mayor variabilidad intra.

A medida que el estadístico F es más grande, se ubica más en la cola de la distribución, por lo que el p-value será menor, con los que se tendría una mayor evidencia en contra de la H0 sobre la igualdad de medias poblacionales.

![](anova2.png){width="534"}

Por lo tanto se concluiría que al menos una de las medias grupales sería significativamente diferente de las otras medias grupales.
El tema es que la prueba de ANOVA no llega hasta ahí, no nos indica qué medias son diferentes.
Para saber qué media(s) es(son) diferente(s) se tiene que hacer un test posterior.

## Post hoc: Test de Tukey

Este test sirve para analizar qué diferencias entre grupos son significativas.
Es decir, reporta todos los emparejamientos posibles entre grupos y en cada pareja corre una prueba t de diferencia de medias y la reporta.

# Ejemplo

En esta sección seguiremos usando el paper de [@lalondeEvaluatingEconometricEvaluations1986] para evaluar los ingresos.
En la sección anterior se encontró que había una diferencia estadísticamente significativa entre los afros y no afros en sus ingresos en 1978.

```{r base LL}
library(rio)
LL <- import("bases/LL.csv")
```

Adicionalmente, se puede evaluar si existen diferencias extrapolables entre aquellos con un grado académico y aquellos que no.
Para esto se vuelve a usar la prueba t entre estos dos grupos.
En primer lugar, se evalúa si las varianzas son iguales o no.
Ojo, el código lanza un mensaje que indica que la variable "degree" no es un factor, y, efectivamente, es importanda como una variable de tipo "int", pero es coercionada como factor, pues R identifica que solo tiene 2 valores.

```{r Levene 1}
library(DescTools)
LeveneTest(LL$re78, LL$nodegree)
```

El resultado indica que se puede rechazar la hipótesis de igualdad de varianzas y asumir que son diferentes.
Con esto se corre la prueba t.

```{r t 1}
t.test(re78 ~ nodegree, data = LL, var.equal=F)
```

Se encuentra que sí hay diferencias entre aquellos con un grado académico y aquellos que no.
Ahora lo que queremos evaluar es si existen diferencias entre los afroamericanos con grado académico y sin grado académico y los no afroamericanos con grado y sin grado.
Para hacer esta evaluación entre 4 grupos, lo primero es construir la variable que es la combinación de las variables "black" y "nodegree".

```{r afro x grado}
LL$axd <-NA
LL$axd[LL$black==0 & LL$nodegree==0] <- 1 #no afro sin grado
LL$axd[LL$black==0 & LL$nodegree==1] <- 2 #no afro con grado
LL$axd[LL$black==1 & LL$nodegree==0] <- 3 #afro sin grado
LL$axd[LL$black==1 & LL$nodegree==1] <- 4 #afro con grado
```

La variable creada es una variable numérica, la que se convierte a factor y se etiqueta.

```{r factor afro x grado}
LL$axd <- as.factor(LL$axd)
levels(LL$axd) <- c("No afro sin grado", "No afro con grado", "Afro sin grado", "Afro con grado")
table(LL$axd)
```

Antes de correr la prueba, es una buena práctica hacer una inspección descriptiva de los ingresos entre estos 4 grupos.

```{r message=FALSE, warning=FALSE}
library(psych)
tabla1 <- describeBy(LL$re78, group=LL$raxd)
tabla1
```

O también se puede hacer una inspección visual.
A primera vista, no parece haber diferencias entre ningún grupo, en cuanto a ingresos.

```{r medias afro x grado}
library(gplots)
plotmeans(LL$re78~LL$axd, connect=F, barwidth=3, xlab="Grupos", ylab="Ingresos 1978",
          main="Ingresos por grupos")
```

Esta observación visual se tiene que confirmar con la prueba de ANOVA.

```{r anova afro x grado}
anova <- aov(LL$re78~LL$axd)
summary(anova)
```

Con la prueba de ANOVA y el p-value correspondiente no se puede rechazar la H0, aunque muy marginalmente.
Este p-value sí sería significativo a 0.10, pero tendríamos una probabilidad mayor de error de tipo I.
Para confirmar esto, se corre la prueba de Tukey para analizar cada emparejamiento.

```{r Tukey afro x grado}
TukeyHSD(anova)
```

En este caso se observa que la diferencia entre afroamericanos con grado y no afroamericanos con grado es la que explica que ANOVA sea marginalmente significativo.

NOTA: Hay ocasiones como esta en que la prueba de ANOVA indica que existe un emparejamiento con una diferencia significativa, y luego, cuando se evalúan los emparejamientos, no se observa esa diferencia.
Eso es debido a que cada emparejamiento de evalúa mediante la prueba t de manera autónoma.

# Para una variable categórica

De la misma manera que en la sección anterior, ANOVA también se puede utilizar de manera **referencial** para evaluar las diferencias de proporciones entre más de 2 grupos.
Por ejemplo, siguiendo con el ejemplo sobre discriminación en CVs [@bertrandAreEmilyGreg2004] que buscan evaluar si hay una discriminación en el mercado laboral entre afroamericanos y angloamericanos y entre hombres y mujeres.
Estos investigadores enviaron CVs manipulando la raza y el género percibidos mediante nombres claramente asociados a los afroamericanos y nombres claramente asociados a angloamericanos, tanto nombres masculinos como femeninos.

En la sección anterior se encontró que sí había un sesgo en contra de los afroamericanos, pero que no se podía decir que hubiera un sesgo en contra de las mujeres en el mercado laboral.
En los resultados comparando género, cuando se compara hombre y mujeres, en ambos grupos hay afroamericanos y angloamericanos.

Una posibilidad es que haya una discriminación en el mercado laboral aún mayor en contra de las mujeres afroamericanos con respecto a los hombres afroamericanos, y de estos con respecto a los angloamericanos, sean hombre o mujeres.
Es decir, que la tasa de respuesta a CVs sería menor para las mujeres afro que para los hombres afro y estos menores que la tasa de respuesta a los CVs de hombre o mujeres angloamericanos.

Para evaluar esta hipótesis, primero cargamos nuevamente la base de datos.

```{r base, message=FALSE, warning=FALSE}
library(rio)
cv <- import("https://raw.github.com/arturomaldonado/Estadistica_1.0/main/cv.csv")
```

En esta base de datos se tiene la raza y el género como variables separadas.
Para hacer la evaluación que se busca se requiere crear una nueva variable de factor que combine los 4 grupos de raza y género.
Se tiene que prestar atención a la forma de calcular una variable como condición de las variables "race" y "sex", ambas de tipo "chr".

```{r factor}
cv$rxg <- NA
cv$rxg[cv$race=="black" & cv$sex=="female"] <- 1
cv$rxg[cv$race=="black" & cv$sex=="male"] <- 2
cv$rxg[cv$race=="white" & cv$sex=="female"] <- 3
cv$rxg[cv$race=="white" & cv$sex=="male"] <- 4
cv$rxg = as.factor(cv$rxg)
levels(cv$rxg) <- c("Black woman", "Black man", "White woman", "White man")
table(cv$rxg)
```

Lo primero es recordar que la tasa de respuesta general es de 8% para toda la muestra.

```{r tasa}
mean(cv$call)*100
```

Ahora podemos calcular la tasa de respuesta a los CVs por cada grupo.
Esta comparación se puede guardar en un objeto "tabla1".

```{r tasa por grupos}
library(psych)
tabla2 <- describeBy(cv$call*100, group=cv$rxg)
tabla2
```

También se puede ver esta comparación descriptiva en forma de gráfico.

```{r plot}
library(gplots)
plotmeans(cv$call*100~cv$rxg, connect=F, barwidth=3, xlab="Grupos", ylab="Tasa de respuesta",
          ylim=c(0, 15), main="Tasa de respuesta por grupos")
```

Para comprobar esta comparación "informal" se tiene que correr el test de ANOVA.

```{r anova}
anova2 <- aov(cv$call*100~cv$rxg)
summary(anova2)
```

Se obtiene un estadístico F de 5.97, con lo que se calcula un p-value \< 0.05.
Esto nos lleva a poder rechazar la H0 de igualdad de medias grupales poblacionales.
Por lo tanto concluimos que alguna de estas medias grupales es diferente.

Para saber cuál es diferente se tiene que correr el Test de Tukey.

```{r tukey}
TukeyHSD(anova2)
```

Este test nos brinda resultados por cada emparejamiento.
Se concluye que hay 2 emparejamientos relevantes, que llevan a la conclusión que las mujeres blancas tienen una tasa de respuesta mayor que los hombre y mujeres afro.

Estas diferencias se pueden ver de manera gráfica.

```{r plot Tukey}
plot(TukeyHSD(anova2))
```

Aquellos emparejamientos cuyas líneas no crucen la línea vertical del cero, se puede decir que hay diferencias estadísticamente significativas.
